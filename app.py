import streamlit as st
import cv2
import numpy as np
import pandas as pd

# ã‚°ãƒ©ãƒ•æç”»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªï¼ˆaltair, matplotlib, seabornï¼‰ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚’å‰Šé™¤

st.set_page_config(page_title="Bio-Image Quantifier Pro (Extraction Only)", layout="wide")

if "analysis_history" not in st.session_state:
    st.session_state.analysis_history = []

st.title("ğŸ”¬ Bio-Image Quantifier: Pro Edition (Extraction)")
st.caption("2025å¹´æœ€çµ‚ç‰ˆï¼šè§£æãƒ»ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºå°‚ç”¨ï¼ˆã‚°ãƒ©ãƒ•æ©Ÿèƒ½ãªã—ï¼‰")

# --- è‰²å®šç¾© ---
COLOR_MAP = {
    "èŒ¶è‰² (DAB)": {"lower": np.array([10, 50, 20]), "upper": np.array([30, 255, 255])},
    "ç·‘ (GFP)": {"lower": np.array([35, 50, 50]), "upper": np.array([85, 255, 255])},
    "èµ¤ (RFP)": {"lower": np.array([0, 50, 50]), "upper": np.array([10, 255, 255])},
    "é’ (DAPI)": {"lower": np.array([100, 50, 50]), "upper": np.array([140, 255, 255])}
}

# --- é–¢æ•°ç¾¤ ---
def get_mask(hsv_img, color_name, sens, bright_min):
    if color_name == "èµ¤ (RFP)":
        lower1 = np.array([0, 30, bright_min])
        upper1 = np.array([10 + sens//2, 255, 255])
        lower2 = np.array([170 - sens//2, 30, bright_min])
        upper2 = np.array([180, 255, 255])
        return cv2.inRange(hsv_img, lower1, upper1) | cv2.inRange(hsv_img, lower2, upper2)
    else:
        conf = COLOR_MAP[color_name]
        l = np.clip(conf["lower"] - sens, 0, 255)
        u = np.clip(conf["upper"] + sens, 0, 255)
        l[2] = max(l[2], bright_min)
        return cv2.inRange(hsv_img, l, u)

def get_centroids(mask):
    cnts, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    pts = []
    for c in cnts:
        M = cv2.moments(c)
        if M["m00"] != 0:
            pts.append(np.array([M["m10"]/M["m00"], M["m01"]/M["m00"]]))
    return pts

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ ---
with st.sidebar:
    st.header("Analysis Recipe")
    mode = st.selectbox("è§£æãƒ¢ãƒ¼ãƒ‰ã‚’é¸æŠ:", [
        "1. å˜è‰²é¢ç©ç‡ (Area)",
        "2. ç´°èƒæ ¸ã‚«ã‚¦ãƒ³ãƒˆ (Count)",
        "3. æ±ç”¨å…±å±€åœ¨è§£æ (Colocalization)",
        "4. æ±ç”¨ç©ºé–“è·é›¢è§£æ (Spatial Distance)",
        "5. å‰²åˆãƒˆãƒ¬ãƒ³ãƒ‰è§£æ (Ratio Analysis)"
    ])
    st.divider()

    if mode == "5. å‰²åˆãƒˆãƒ¬ãƒ³ãƒ‰è§£æ (Ratio Analysis)":
        st.markdown("### ğŸ”¢ æ¡ä»¶è¨­å®š (Batch)")
        trend_metric = st.radio("æ¸¬å®šå¯¾è±¡:", ["å…±å±€åœ¨ç‡ (Colocalization)", "é¢ç©ç‡ (Area)"])
        ratio_val = st.number_input("ä»Šå›ã®æ•°å€¤æ¡ä»¶ (å‰²åˆ/æ¿ƒåº¦):", value=0, step=10)
        ratio_unit = st.text_input("å˜ä½:", value="%", key="unit")
        sample_group = f"{ratio_val}{ratio_unit}"
        st.info(f"ãƒ©ãƒ™ãƒ«: **{sample_group}**")
        st.divider()
        if trend_metric == "å…±å±€åœ¨ç‡ (Colocalization)":
            c1, c2 = st.columns(2)
            with c1:
                target_a = st.selectbox("CH-A (åŸºæº–):", list(COLOR_MAP.keys()), index=3) 
                sens_a = st.slider("Aæ„Ÿåº¦", 5, 50, 20, key="t_s_a")
                bright_a = st.slider("Aè¼åº¦", 0, 255, 60, key="t_b_a")
            with c2:
                target_b = st.selectbox("CH-B (å¯¾è±¡):", list(COLOR_MAP.keys()), index=2) 
                sens_b = st.slider("Bæ„Ÿåº¦", 5, 50, 20, key="t_s_b")
                bright_b = st.slider("Bè¼åº¦", 0, 255, 60, key="t_b_b")
        else:
            target_a = st.selectbox("è§£æè‰²:", list(COLOR_MAP.keys()), index=2)
            sens_a = st.slider("æ„Ÿåº¦", 5, 50, 20, key="t_s_a")
            bright_a = st.slider("è¼åº¦", 0, 255, 60, key="t_b_a")
    else:
        sample_group = st.text_input("ã‚°ãƒ«ãƒ¼ãƒ—å (Xè»¸):", value="Control")
        st.divider()
        if mode == "1. å˜è‰²é¢ç©ç‡ (Area)":
            target_a = st.selectbox("è§£æè‰²:", list(COLOR_MAP.keys()))
            sens_a = st.slider("æ„Ÿåº¦", 5, 50, 20)
            bright_a = st.slider("è¼åº¦", 0, 255, 60)
        elif mode == "2. ç´°èƒæ ¸ã‚«ã‚¦ãƒ³ãƒˆ (Count)":
            min_size = st.slider("æœ€å°ã‚µã‚¤ã‚º(px)", 10, 500, 50)
            bright_count = st.slider("è¼åº¦ã—ãã„å€¤", 0, 255, 50)
        elif mode == "3. æ±ç”¨å…±å±€åœ¨è§£æ (Colocalization)":
            c1, c2 = st.columns(2)
            with c1:
                target_a = st.selectbox("CH-A (åŸºæº–):", list(COLOR_MAP.keys()), index=3)
                sens_a = st.slider("Aæ„Ÿåº¦", 5, 50, 20)
                bright_a = st.slider("Aè¼åº¦", 0, 255, 60)
            with c2:
                target_b = st.selectbox("CH-B (å¯¾è±¡):", list(COLOR_MAP.keys()), index=2)
                sens_b = st.slider("Bæ„Ÿåº¦", 5, 50, 20)
                bright_b = st.slider("Bè¼åº¦", 0, 255, 60)
        elif mode == "4. æ±ç”¨ç©ºé–“è·é›¢è§£æ (Spatial Distance)":
            target_a = st.selectbox("èµ·ç‚¹A:", list(COLOR_MAP.keys()), index=2)
            target_b = st.selectbox("å¯¾è±¡B:", list(COLOR_MAP.keys()), index=3)
            sens_common = st.slider("è‰²æ„Ÿåº¦", 5, 50, 20)
            bright_common = st.slider("è¼åº¦", 0, 255, 60)

    if st.button("å±¥æ­´ã‚’å…¨æ¶ˆå»"):
        st.session_state.analysis_history = []
        st.rerun()

# --- ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ ---
uploaded_files = st.file_uploader("ç”»åƒã‚’ã¾ã¨ã‚ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["jpg", "png", "tif"], accept_multiple_files=True)

if uploaded_files:
    st.success(f"{len(uploaded_files)} æšã®ç”»åƒã‚’è§£æä¸­...")
    batch_results = []
    
    for i, file in enumerate(uploaded_files):
        file.seek(0)
        file_bytes = np.asarray(bytearray(file.read()), dtype=np.uint8)
        img_bgr = cv2.imdecode(file_bytes, 1)
        
        if img_bgr is not None:
            img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)
            img_hsv = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HSV)
            
            val, unit = 0.0, ""
            res_display = img_rgb.copy()
            
            # --- è§£æãƒ­ã‚¸ãƒƒã‚¯ ---
            if mode == "1. å˜è‰²é¢ç©ç‡ (Area)" or (mode.startswith("5.") and trend_metric == "é¢ç©ç‡ (Area)"):
                mask = get_mask(img_hsv, target_a, sens_a, bright_a)
                val = (cv2.countNonZero(mask) / (img_rgb.shape[0] * img_rgb.shape[1])) * 100
                unit = f"% Area"
                res_display = mask
            elif mode == "2. ç´°èƒæ ¸ã‚«ã‚¦ãƒ³ãƒˆ (Count)":
                gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)
                _, th = cv2.threshold(gray, bright_count, 255, cv2.THRESH_BINARY)
                blur = cv2.GaussianBlur(gray, (5,5), 0)
                _, otsu = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)
                final = cv2.bitwise_and(th, otsu)
                cnts, _ = cv2.findContours(final, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                valid = [c for c in cnts if cv2.contourArea(c) > min_size]
                val, unit = len(valid), "cells"
                cv2.drawContours(res_display, valid, -1, (0,255,0), 2)
            elif mode == "3. æ±ç”¨å…±å±€åœ¨è§£æ (Colocalization)" or (mode.startswith("5.") and trend_metric == "å…±å±€åœ¨ç‡ (Colocalization)"):
                mask_a = get_mask(img_hsv, target_a, sens_a, bright_a)
                mask_b = get_mask(img_hsv, target_b, sens_b, bright_b)
                coloc = cv2.bitwise_and(mask_a, mask_b)
                denom = cv2.countNonZero(mask_a)
                val = (cv2.countNonZero(coloc) / denom * 100) if denom > 0 else 0
                unit = f"% Coloc"
                res_display = cv2.merge([mask_b, mask_a, np.zeros_like(mask_a)])
            elif mode == "4. æ±ç”¨ç©ºé–“è·é›¢è§£æ (Spatial Distance)":
                mask_a = get_mask(img_hsv, target_a, sens_common, bright_common)
                mask_b = get_mask(img_hsv, target_b, sens_common, bright_common)
                pts_a, pts_b = get_centroids(mask_a), get_centroids(mask_b)
                if pts_a and pts_b:
                    val = np.mean([np.min([np.linalg.norm(pa - pb) for pb in pts_b]) for pa in pts_a])
                else: val = 0
                unit = "px Dist"
                res_display = cv2.addWeighted(img_rgb, 0.6, cv2.merge([mask_a, mask_b, np.zeros_like(mask_a)]), 0.4, 0)
            
            # --- 0æœªæº€é˜²æ­¢ ---
            val = max(0.0, val)

            entry = {
                "Group": sample_group,
                "Value": val,
                "Unit": unit,
                "Is_Trend": mode.startswith("5."),
                "Ratio_Value": ratio_val if mode.startswith("5.") else 0
            }
            batch_results.append(entry)
            
            # --- Expanderã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’å›ºå®š ---
            with st.expander(f"ğŸ“· Image {i+1}: {file.name}", expanded=True):
                st.markdown(f"### Result: **{val:.2f} {unit}**")
                c1, c2 = st.columns(2)
                c1.image(img_rgb, caption="Original", use_container_width=True)
                c2.image(res_display, caption="Analyzed", use_container_width=True)

    if st.button(f"ãƒ‡ãƒ¼ã‚¿ {len(batch_results)} ä»¶ã‚’è¿½åŠ ", type="primary"):
        st.session_state.analysis_history.extend(batch_results)
        st.rerun()

# --- ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤ºã‚»ã‚¯ã‚·ãƒ§ãƒ³ (ãƒ‡ãƒ¼ã‚¿ã®ã¿) ---
if st.session_state.analysis_history:
    st.divider()
    st.header("ğŸ’¾ Data Export")
    
    df = pd.DataFrame(st.session_state.analysis_history)
    df["Value"] = df["Value"].clip(lower=0) # å¼·åˆ¶0è£œæ­£

    # ã‚°ãƒ©ãƒ•è¡¨ç¤ºã‚³ãƒ¼ãƒ‰ã¯å®Œå…¨ã«å‰Šé™¤ã•ã‚Œã¾ã—ãŸ

    st.dataframe(df, use_container_width=True)
    st.download_button("ğŸ“¥ CSVãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜", df.to_csv(index=False).encode('utf-8'), "data.csv", "text/csv")
